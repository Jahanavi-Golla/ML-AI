{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 7736,
     "status": "ok",
     "timestamp": 1678656855966,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "JQ61a7HLoX7a"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5s4hxl-HdZd"
   },
   "source": [
    "**Implementing neural networks from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1678656856803,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "-9hhedHxHXwP"
   },
   "outputs": [],
   "source": [
    "# functions for sigmoid and sigmoid_derivative\n",
    "def sigmoid(z) :\n",
    "  return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative (z):\n",
    "  return sigmoid(z) * (1.0 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1678656856911,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "4v3RmmN6Hy7C"
   },
   "outputs": [],
   "source": [
    "# funtion to train the data\n",
    "def train(X, y, n_hidden, learning_rate, n_iter):\n",
    "    m, n_input = X.shape\n",
    "    W1 = np.random.rand(n_input, n_hidden)\n",
    "    b1 = np. zeros ((1, n_hidden))\n",
    "    W2 = np.random. randn (n_hidden, 1)\n",
    "    b2 = np.zeros ((1, 1))\n",
    "    for i in range(1, n_iter+1):\n",
    "      Z2 = np .matmul(X, W1) + b1\n",
    "      A2 = sigmoid (Z2)\n",
    "      Z3 = np .matmul (A2, W2) + b2\n",
    "      A3 = Z3\n",
    "      dZ3 = A3 - y\n",
    "      dW2 = np .matmul(A2.T, dZ3)\n",
    "      db2 = np. sum (dZ3, axis=0, keepdims=True)\n",
    "      dZ2 = np.matmul (dZ3, W2.T) * sigmoid_derivative (Z2)\n",
    "      dW1 = np. matmul(X.T, dZ2)\n",
    "      db1 = np. sum(dZ2, axis=0)\n",
    "      W2 = W2 - learning_rate * dW2 / m\n",
    "      b2 = b2 - learning_rate * db2 / m\n",
    "      W1 = W1 - learning_rate * dW1 / m\n",
    "      b1 = b1 - learning_rate * db1 / m\n",
    "      if i % 100 == 0:\n",
    "        cost = np. mean ((y - A3) ** 2)\n",
    "        print('Iteration %i, training loss: %f' %\n",
    "        (i, cost))\n",
    "        model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2' : b2}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1678656857039,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "gUPW8JA2Ky-x",
    "outputId": "e267d880-9f1d-4460-fd1a-aa1981c371b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "boston = pd.read_csv('boston_house_prices.csv')\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678656857039,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "FnidSK33Qb7l"
   },
   "outputs": [],
   "source": [
    "X_train = boston.iloc[:-10, :-1].values\n",
    "X_test=boston.iloc[-10:,:-1].values\n",
    "y_train=boston.iloc[:-10,-1:].values\n",
    "y_test=boston.iloc[-10:,-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1678656858011,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "T4_0a-ymOIWm"
   },
   "outputs": [],
   "source": [
    "# Feature scaling using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6676,
     "status": "ok",
     "timestamp": 1678656864680,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "LcWfJqqtMG_d",
    "outputId": "ab254bc8-d69c-4ff6-dc1e-a046c0c6714d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, training loss: 12.940062\n",
      "Iteration 200, training loss: 9.548830\n",
      "Iteration 300, training loss: 8.213685\n",
      "Iteration 400, training loss: 7.308816\n",
      "Iteration 500, training loss: 6.627400\n",
      "Iteration 600, training loss: 6.027228\n",
      "Iteration 700, training loss: 5.424473\n",
      "Iteration 800, training loss: 5.016720\n",
      "Iteration 900, training loss: 4.653899\n",
      "Iteration 1000, training loss: 4.388297\n",
      "Iteration 1100, training loss: 4.176738\n",
      "Iteration 1200, training loss: 3.995087\n",
      "Iteration 1300, training loss: 3.836603\n",
      "Iteration 1400, training loss: 3.698273\n",
      "Iteration 1500, training loss: 3.575729\n",
      "Iteration 1600, training loss: 3.464894\n",
      "Iteration 1700, training loss: 3.362927\n",
      "Iteration 1800, training loss: 3.268378\n",
      "Iteration 1900, training loss: 3.180213\n",
      "Iteration 2000, training loss: 3.096994\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 20\n",
    "learning_rate = 0.1\n",
    "n_iter = 2000\n",
    "model = train(X_train, y_train, n_hidden, learning_rate, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1678656864680,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "r2Lgj-18S9J3"
   },
   "outputs": [],
   "source": [
    "def predict(x, model) :\n",
    "    W1 = model['W1']\n",
    "    b1 = model['b1']\n",
    "    W2 = model['W2']\n",
    "    b2 = model['b2']\n",
    "    A2 = sigmoid(np.matmul(x, W1) + b1)\n",
    "    A3 = np.matmul(A2, W2) + b2\n",
    "    return A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1678656864680,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "gWCC2xoHS-oM"
   },
   "outputs": [],
   "source": [
    "# predicting the data\n",
    "y_pred = predict(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1678656864681,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "f_ha1I9oTWqQ",
    "outputId": "e6c38164-ce70-4d5e-c3d1-aef8a4bd5893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.7749759 ],\n",
       "       [20.9690382 ],\n",
       "       [22.62662422],\n",
       "       [21.21842735],\n",
       "       [21.09401768],\n",
       "       [22.48626373],\n",
       "       [19.46455286],\n",
       "       [29.27424762],\n",
       "       [25.87967102],\n",
       "       [18.54510089]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the predicted data\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1678656864762,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "mSfRIXF6TY-n",
    "outputId": "ffd88fba-b396-4921-92a2-f1efca1bb638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.7],\n",
       "       [18.3],\n",
       "       [21.2],\n",
       "       [17.5],\n",
       "       [16.8],\n",
       "       [22.4],\n",
       "       [20.6],\n",
       "       [23.9],\n",
       "       [22. ],\n",
       "       [11.9]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the tested data\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yP3GAkszUSpl"
   },
   "source": [
    "### Implementing neural networks with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1678656865128,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "ZM8jceDsT3bV"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "nn_scikit = MLPRegressor(hidden_layer_sizes=(16, 8),activation='relu',\n",
    "                         solver= 'adam', learning_rate_init=0.001, random_state=42, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7173,
     "status": "ok",
     "timestamp": 1678656872297,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "ch5hkUGiT3ce",
    "outputId": "e5029c91-3c10-4218-d93c-63b8dc77c7e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAHANAVI\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.79582331 18.55538023 21.07961496 19.21362606 18.50955771 23.5608387\n",
      " 22.27916529 27.11909153 24.70251262 22.05522035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAHANAVI\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn_scikit.fit(X_train, y_train)\n",
    "predictions = nn_scikit.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1678656872298,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "poy2n-TRT3es",
    "outputId": "856fa49c-fcfa-4a39-b623-dd0f8834309d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.89149787538776\n"
     ]
    }
   ],
   "source": [
    "print(np.mean((y_test - predictions) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5wctHc3U1S5"
   },
   "source": [
    "## Implementing neural networks with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1678656872298,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "NttDmD1iT3h3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1678656872595,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "NISBU493T3k_"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(units=20, activation='relu'), \n",
    "                           keras.layers.Dense(units=8, activation='relu'),keras.layers. Dense(units=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1678656872727,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "WOLT8hivT3oC"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer=tf.keras.optimizers.Adam (0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44960,
     "status": "ok",
     "timestamp": 1678656917683,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "kt477HCxT3q-",
    "outputId": "c1b06614-f3fc-4475-9034-3ec8e4681063",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "16/16 [==============================] - 2s 6ms/step - loss: 387.6885\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 83.5413\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0722\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 22.5090\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 18.3381\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 16.4381\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14.1813\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 14.5776\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12.5013\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.4618\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.2311\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11.0587\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.5894\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.6753\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.9065\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.2742\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.3519\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 9.0545\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.8102\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.0480\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.6926\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.9613\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.6498\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.5676\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 8.4762\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.3291\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.6292\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.0229\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.6173\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.5848\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.6024\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0340\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0774\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6641\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8049\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.9562\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7929\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.4201\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.6006\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.3830\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.7302\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.5221\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.8286\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.0653\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.7940\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.4446\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.5965\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.3557\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.3277\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.7467\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.1699\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1223\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.1777\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.3293\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.8398\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.1041\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.1567\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.9827\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.5602\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.6736\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7949\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.6830\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.8540\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.7937\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.8565\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.5857\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6410\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.3298\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.5440\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.1286\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.8328\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.9863\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.3470\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.6940\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.5838\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.6012\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.8276\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.4355\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.0413\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.4334\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.8122\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7417\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.2189\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.9854\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 6.5977\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.2768\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6.0560\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.4656\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6.8584\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 6.3133\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 6.2066\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.4158\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.7170\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.9059\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.7353\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.1895\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.0365\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 7.6496\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.4007\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.2222\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.7861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.6813\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.0356\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.3381\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.3090\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7938\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.6574\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.7240\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.6097\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0781\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0703\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.4838\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.6128\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.8996\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.7224\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9630\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8561\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.1613\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9748\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.4569\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3791\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.6209\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.5847\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3719\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3398\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.8714\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.2934\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.5028\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3884\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.3474\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.5764\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0516\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.7532\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.2591\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0436\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.6550\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.5015\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3357\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.1647\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9903\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.1422\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.1309\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.0162\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.9078\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0155\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9193\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.0044\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0344\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.8068\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.5240\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.9200\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.3786\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.6362\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.3841\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.4318\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 4.7690\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 4.9008\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 4.7376\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.2141\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.1637\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.3009\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.6518\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.4215\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.4784\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.7020\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.6118\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.5038\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.3620\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6367\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7319\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.5130\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3810\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.5718\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.7328\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.8505\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3903\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.3235\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.8389\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1077\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6151\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.1511\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4936\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.8669\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1270\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7866\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3647\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9360\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0096\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2246\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1222\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1447\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7507\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4539\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.2734\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.5106\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3678\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2805\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2639\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.5812\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.5777\n",
      "Epoch 201/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6148\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2712\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6385\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1616\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6143\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2822\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7355\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.6407\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8836\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1351\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1281\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9337\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8214\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8660\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0641\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1648\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.5788\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2006\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.0411\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3024\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3419\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9614\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0329\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.6668\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2396\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0077\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7888\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7700\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3679\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8264\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9370\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.4552\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1618\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8474\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0595\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0579\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.8542\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7547\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.0717\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6555\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.6311\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.6700\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.4594\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0838\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1449\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6297\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.5364\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.0225\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9117\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4219\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3815\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8341\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.6098\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4303\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5738\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8525\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8303\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6382\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4418\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5229\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5581\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9036\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.7414\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.4529\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.2511\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5648\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.9461\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5603\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3811\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3178\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6427\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.5118\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.5878\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.5258\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 3.7696\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.6581\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2047\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2492\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.1646\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.3424\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.3671\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4365\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4889\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.7457\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.9027\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.1541\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.1219\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.0157\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7103\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.8347\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.4027\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.9599\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5901\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5427\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1864\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5619\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1414\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3446\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4700\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c4e872c4f0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(X_train, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1678656917684,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "7t3E5EC3T3uG",
    "outputId": "6e4ab748-91ad-498b-eb03-b848f2bbfd86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 162ms/step\n",
      "[17.731482 19.874907 21.859411 20.081741 20.481659 26.139755 22.837294\n",
      " 31.345085 29.167486 22.425608]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)[:, 0]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1678656917684,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "fsOE9VfDT3xO",
    "outputId": "af6a0d32-a992-4267-b828-997930dcbaa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.15087210338898\n"
     ]
    }
   ],
   "source": [
    "print(np.mean((y_test - predictions) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZBF-23HVkd_"
   },
   "source": [
    "## Preventing overfitting in neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1678656917814,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "pExva8VhT30G"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(units=32, activation='relu'), \n",
    "                           tf.keras.layers.Dropout(0.5), keras.layers.Dense(units=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAK8C4_YWtdo"
   },
   "source": [
    "### Predicting stock prices with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1678656917814,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "bJu_4WVuT33N",
    "outputId": "bb5e397a-c50e-4cdd-bc79-7b4bbccd6268"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-12-01</th>\n",
       "      <td>10806.0</td>\n",
       "      <td>10934.9</td>\n",
       "      <td>10806.0</td>\n",
       "      <td>10912.6</td>\n",
       "      <td>256932865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-02</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>10921.4</td>\n",
       "      <td>10861.7</td>\n",
       "      <td>10877.5</td>\n",
       "      <td>214888854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-05</th>\n",
       "      <td>10877.0</td>\n",
       "      <td>10877.0</td>\n",
       "      <td>10810.7</td>\n",
       "      <td>10835.0</td>\n",
       "      <td>237430947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-06</th>\n",
       "      <td>10835.4</td>\n",
       "      <td>10936.2</td>\n",
       "      <td>10835.4</td>\n",
       "      <td>10856.9</td>\n",
       "      <td>264721465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-07</th>\n",
       "      <td>10856.9</td>\n",
       "      <td>10868.1</td>\n",
       "      <td>10764.0</td>\n",
       "      <td>10810.9</td>\n",
       "      <td>243543206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-08</th>\n",
       "      <td>10808.4</td>\n",
       "      <td>10847.2</td>\n",
       "      <td>10729.7</td>\n",
       "      <td>10755.1</td>\n",
       "      <td>253313750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-09</th>\n",
       "      <td>10751.8</td>\n",
       "      <td>10806.0</td>\n",
       "      <td>10729.9</td>\n",
       "      <td>10778.6</td>\n",
       "      <td>238907145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close     Volume\n",
       "Date                                                     \n",
       "2005-12-01  10806.0  10934.9  10806.0  10912.6  256932865\n",
       "2005-12-02  10912.0  10921.4  10861.7  10877.5  214888854\n",
       "2005-12-05  10877.0  10877.0  10810.7  10835.0  237430947\n",
       "2005-12-06  10835.4  10936.2  10835.4  10856.9  264721465\n",
       "2005-12-07  10856.9  10868.1  10764.0  10810.9  243543206\n",
       "2005-12-08  10808.4  10847.2  10729.7  10755.1  253313750\n",
       "2005-12-09  10751.8  10806.0  10729.9  10778.6  238907145"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data=pd.read_csv('20051201_20051210.csv',index_col='Date')\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1678656917815,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "W3hpnSd7T36Q"
   },
   "outputs": [],
   "source": [
    "def add_original_feature(df, df_new):\n",
    "    df_new['open'] = df['Open']\n",
    "    df_new['open_1'] = df['Open'].shift(1)\n",
    "    df_new['close_1']= df['Close'].shift(1)\n",
    "    df_new['high_1'] = df['High'].shift(1)\n",
    "    df_new['low_ 1'] = df['Low'].shift(1)\n",
    "    df_new['volume 1'] = df['Volume'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678656917815,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "xuZs34fJT39O"
   },
   "outputs": [],
   "source": [
    "def add_avg_price(df,df_new):\n",
    "    df_new['avg_price_5']   = df['Close'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_price_30']  = df['Close'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_price_365'] = df ['Close'].rolling(252).mean().shift(1)\n",
    "    df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n",
    "    df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n",
    "    df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678656917816,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "Y2O3HPPcT4AD"
   },
   "outputs": [],
   "source": [
    "def add_avg_volume(df,df_new):\n",
    "    df_new['avg_volume_5'] =  df['Volume'].rolling(5).mean().shift (1)\n",
    "    df_new['avg_volume_30'] =  df['Volume'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_volume_365'] = df['Volume'].rolling(252).mean().shift(1)\n",
    "    df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n",
    "    df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n",
    "    df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678656917934,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "ZoLzWvrgT4Ku"
   },
   "outputs": [],
   "source": [
    "def add_std_price(df,df_new):\n",
    "    df_new['std_price_5'] = df['Close'].rolling(5).std().shift(1)\n",
    "    df_new['std_price_30'] = df['Close'].rolling(21).std().shift(1)\n",
    "    df_new['std_price_365'] = df['Close'].rolling(252).std().shift (1)\n",
    "    df_new['ratio_std_price_5_30'] =df_new['std_price_5'] / df_new['std_price_30']\n",
    "    df_new['ratio_std price_5_365'] =df_new['std_price_5'] / df_new['std_price_365']\n",
    "    df_new['ratio_std_price_30_365'] =df_new['std_price_30'] / df_new['std_price_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678656917935,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "bksAVQO4T4Mp"
   },
   "outputs": [],
   "source": [
    "def add_std_volume(df,df_new):\n",
    "    df_new['std_volume_5'] = df['Volume'].rolling(5).std().shift(1)\n",
    "    df_new['std_volume_30'] = df['Volume' ].rolling(21).std().shift(1)\n",
    "    df_new['std_volume_365'] = df['Volume'].rolling(252).std().shift(1)\n",
    "    df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n",
    "    df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']\n",
    "    df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1678656918013,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "C-McdqwST4Oo"
   },
   "outputs": [],
   "source": [
    "def  add_return_feature(df, df_new):\n",
    "    df_new['return_1'] = ((df['Close'] - df['Close'].shift (1)) / df['Close'].shift(1)).shift (1)\n",
    "    df_new['return_5'] = ((df['Close'] - df['Close'].shift (5))/ df['Close'].shift(5)).shift(1)\n",
    "    df_new['return_30'] = ((df['Close'] - df['Close'].shift (21)) / df['Close'].shift(21)).shift (1)\n",
    "    df_new['return_365'] = ((df['Close'] - df['Close'].shift(252)) / df['Close'].shift(252)).shift (1)\n",
    "    df_new['moving_avg_5'] = df_new['return_1'].rolling(5).mean().shift(1)\n",
    "    df_new['moving_avg_30'] = df_new['return_1'].rolling (21).mean().shift (1)\n",
    "    df_new[ 'moving_avg 365'] = df_new['return_1'].rolling(252).mean().shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678656918013,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "YfsnZ2klT4Q7"
   },
   "outputs": [],
   "source": [
    "def generate_features(df):   \n",
    "    df_new = pd.DataFrame()\n",
    "    add_original_feature(df,df_new)\n",
    "    add_avg_price(df, df_new)\n",
    "    add_avg_volume(df, df_new) \n",
    "    add_std_price(df, df_new) \n",
    "    add_std_volume(df, df_new) \n",
    "    add_return_feature(df,df_new)\n",
    "    df_new['close'] = df['Close']\n",
    "    df_new = df_new.dropna(axis=0)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678656918013,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "G4ru03QdT4Tn"
   },
   "outputs": [],
   "source": [
    "data_raw=pd.read_csv('19880101_20191231.csv',index_col='Date')\n",
    "data = generate_features(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1678656918096,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "osQNksFjT4We",
    "outputId": "fdd45a17-7a46-4dc9-e3e0-996dfbd2f0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              open  open_1  close_1  high_1  low_ 1    volume 1  avg_price_5  \\\n",
      "Date                                                                           \n",
      "1989-01-04  2146.6  2168.4   2144.6  2168.4  2127.1  17302883.0      2165.00   \n",
      "1989-01-05  2177.7  2146.6   2177.7  2183.4  2146.6  15714720.0      2168.00   \n",
      "1989-01-06  2190.5  2177.7   2190.5  2205.2  2173.0  20303094.0      2172.82   \n",
      "1989-01-09  2194.3  2190.5   2194.3  2213.8  2182.3  16494441.0      2175.14   \n",
      "1989-01-10  2199.5  2194.3   2199.5  2209.1  2185.0  18410324.0      2181.32   \n",
      "\n",
      "            avg_price_30  avg_price_365  ratio_avg_price_5_30  ...  \\\n",
      "Date                                                           ...   \n",
      "1989-01-04      2150.624       2062.113                 1.007  ...   \n",
      "1989-01-05      2154.690       2062.668                 1.006  ...   \n",
      "1989-01-06      2157.867       2063.218                 1.007  ...   \n",
      "1989-01-09      2160.005       2064.341                 1.007  ...   \n",
      "1989-01-10      2162.190       2065.351                 1.009  ...   \n",
      "\n",
      "            ratio_std_volume_5_365  ratio_std_volume_30_365  return_1  \\\n",
      "Date                                                                    \n",
      "1989-01-04                   0.563                    0.723    -0.011   \n",
      "1989-01-05                   0.474                    0.724     0.015   \n",
      "1989-01-06                   0.580                    0.748     0.006   \n",
      "1989-01-09                   0.516                    0.746     0.002   \n",
      "1989-01-10                   0.279                    0.742     0.002   \n",
      "\n",
      "            return_5  return_30  return_365  moving_avg_5  moving_avg_30  \\\n",
      "Date                                                                       \n",
      "1989-01-04    -0.011      0.020       0.056         0.001          0.001   \n",
      "1989-01-05     0.007      0.041       0.069        -0.002          0.001   \n",
      "1989-01-06     0.011      0.031       0.068         0.001          0.002   \n",
      "1989-01-09     0.005      0.021       0.148         0.002          0.001   \n",
      "1989-01-10     0.014      0.021       0.131         0.001          0.001   \n",
      "\n",
      "            moving_avg 365   close  \n",
      "Date                                \n",
      "1989-01-04           0.000  2177.7  \n",
      "1989-01-05           0.000  2190.5  \n",
      "1989-01-06           0.000  2194.3  \n",
      "1989-01-09           0.000  2199.5  \n",
      "1989-01-10           0.001  2193.2  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.round(decimals=3).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yL9dNzjafEF0"
   },
   "source": [
    "**Training a simple neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1678656918235,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "TzD3rcsoorQE"
   },
   "outputs": [],
   "source": [
    "data_raw=pd.read_csv('19880101_20191231.csv',index_col='Date')\n",
    "data = generate_features(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1678656918343,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "v5RjET8YouQS"
   },
   "outputs": [],
   "source": [
    "start_train = '1988-01-01'\n",
    "end_train = '2018-12-31'\n",
    "start_test = '2019-01-01'\n",
    "end_test = '2019-12-31'\n",
    "data_train = data.loc[start_train:end_train]\n",
    "X_train = data_train.drop('close', axis=1).values\n",
    "y_train = data_train['close'].values\n",
    "data_test = data.loc[start_test:end_test]\n",
    "X_test = data_test.drop('close', axis=1) . values\n",
    "y_test = data_test['close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678656918343,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "57IpWFqzp7bo"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled_train = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678656918343,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "msc8OE--qJNL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential ([\n",
    "  Dense (units=32, activation='relu'),\n",
    "  Dense (units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1678656918343,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "GPU3PmLzrK0D"
   },
   "outputs": [],
   "source": [
    "model.compile(loss= 'mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67469,
     "status": "ok",
     "timestamp": 1678656985808,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "0eRV8tsvr1HX",
    "outputId": "050d3693-e319-4e1c-f767-2d46d8c91bd6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "237/237 [==============================] - 2s 4ms/step - loss: 33165426.0000\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2091566.3750\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 490141.2500\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 166594.4062\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 81030.9062\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 48613.6992\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 34827.4219\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 29006.2109\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 26850.3887\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 25973.2090\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 28413.3301\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 23037.7559\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 23227.4121\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 28935.3945\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 30662.1387\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 26992.2949\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 30062.6270\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 30558.7363\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 30087.8477\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 29019.9180\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 30076.1602\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 27752.6348\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 32274.1270\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 26161.4023\n",
      "Epoch 25/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 27998.2832\n",
      "Epoch 26/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 29793.0293\n",
      "Epoch 27/100\n",
      "237/237 [==============================] - 2s 9ms/step - loss: 30033.2441\n",
      "Epoch 28/100\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 30166.6055\n",
      "Epoch 29/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 27402.1660\n",
      "Epoch 30/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 37831.1992\n",
      "Epoch 31/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 24161.3906\n",
      "Epoch 32/100\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 25143.9238\n",
      "Epoch 33/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 27162.4512\n",
      "Epoch 34/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 26054.5312\n",
      "Epoch 35/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 24498.1191\n",
      "Epoch 36/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 27627.3457\n",
      "Epoch 37/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 27807.9805\n",
      "Epoch 38/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 26306.4023\n",
      "Epoch 39/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 28856.0430\n",
      "Epoch 40/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 23976.5566\n",
      "Epoch 41/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 24545.7363\n",
      "Epoch 42/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 27849.6055\n",
      "Epoch 43/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 21282.9102\n",
      "Epoch 44/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 25691.9277\n",
      "Epoch 45/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 24077.3945\n",
      "Epoch 46/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 32185.0391\n",
      "Epoch 47/100\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 24227.0039\n",
      "Epoch 48/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 22733.0371\n",
      "Epoch 49/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 27678.1797\n",
      "Epoch 50/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 24792.0703\n",
      "Epoch 51/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 24208.7559\n",
      "Epoch 52/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 23744.8340\n",
      "Epoch 53/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 23150.0215\n",
      "Epoch 54/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 25727.8320\n",
      "Epoch 55/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 24348.7520\n",
      "Epoch 56/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 22655.8047\n",
      "Epoch 57/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 24188.8105\n",
      "Epoch 58/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 25960.7129\n",
      "Epoch 59/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 23891.5273\n",
      "Epoch 60/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 22683.1602\n",
      "Epoch 61/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 22428.2891\n",
      "Epoch 62/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 20834.0527\n",
      "Epoch 63/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 22660.0996\n",
      "Epoch 64/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 23720.9863\n",
      "Epoch 65/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 21531.7012\n",
      "Epoch 66/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 23397.1992\n",
      "Epoch 67/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 23071.2480\n",
      "Epoch 68/100\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 28051.7949\n",
      "Epoch 69/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 19884.3945\n",
      "Epoch 70/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 22517.7539\n",
      "Epoch 71/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 27673.7012\n",
      "Epoch 72/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 26070.9863\n",
      "Epoch 73/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 21270.3457\n",
      "Epoch 74/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 20962.9922\n",
      "Epoch 75/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 20910.2949\n",
      "Epoch 76/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 19057.6348\n",
      "Epoch 77/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 22211.5547\n",
      "Epoch 78/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 23272.1738\n",
      "Epoch 79/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 21507.9629\n",
      "Epoch 80/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 21637.8691\n",
      "Epoch 81/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 22616.0469\n",
      "Epoch 82/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 20642.8262\n",
      "Epoch 83/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 20300.3848\n",
      "Epoch 84/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 24154.8027\n",
      "Epoch 85/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 20782.6543\n",
      "Epoch 86/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 20689.1348\n",
      "Epoch 87/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 21808.6719\n",
      "Epoch 88/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 24915.2500\n",
      "Epoch 89/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 22409.6328\n",
      "Epoch 90/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 21620.4375\n",
      "Epoch 91/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 21365.9395\n",
      "Epoch 92/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 21859.2969\n",
      "Epoch 93/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 19689.1582\n",
      "Epoch 94/100\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 24454.6328\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 1s 5ms/step - loss: 22194.5703\n",
      "Epoch 96/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 18959.4727\n",
      "Epoch 97/100\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 21052.9062\n",
      "Epoch 98/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 19907.6992\n",
      "Epoch 99/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 19640.9160\n",
      "Epoch 100/100\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 20885.2988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c4eda5fa60>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_scaled_train, y_train, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1678656985959,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "ix32Za2pvvqQ",
    "outputId": "88198fbf-fce1-427e-9368-5276ba5c6304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "[[23656.637]\n",
      " [23609.275]\n",
      " [23124.469]\n",
      " [23808.76 ]\n",
      " [23895.469]\n",
      " [24134.549]\n",
      " [24169.055]\n",
      " [24288.75 ]\n",
      " [24268.428]\n",
      " [24225.648]\n",
      " [24415.607]\n",
      " [24525.674]\n",
      " [24725.203]\n",
      " [24983.97 ]\n",
      " [24737.895]\n",
      " [24902.045]\n",
      " [24873.395]\n",
      " [24994.557]\n",
      " [24749.604]\n",
      " [24936.729]\n",
      " [25296.125]\n",
      " [25198.936]\n",
      " [25334.232]\n",
      " [25503.225]\n",
      " [25673.213]\n",
      " [25606.938]\n",
      " [25419.498]\n",
      " [25409.736]\n",
      " [25439.094]\n",
      " [25788.012]\n",
      " [25872.217]\n",
      " [25792.855]\n",
      " [26222.844]\n",
      " [26228.488]\n",
      " [26276.822]\n",
      " [26199.62 ]\n",
      " [26413.5  ]\n",
      " [26463.455]\n",
      " [26391.143]\n",
      " [26321.832]\n",
      " [26282.9  ]\n",
      " [26409.04 ]\n",
      " [26160.855]\n",
      " [26152.514]\n",
      " [26028.81 ]\n",
      " [25791.096]\n",
      " [25694.24 ]\n",
      " [25901.127]\n",
      " [25908.75 ]\n",
      " [26032.17 ]\n",
      " [26047.81 ]\n",
      " [26049.785]\n",
      " [26192.018]\n",
      " [26189.307]\n",
      " [26010.045]\n",
      " [26177.904]\n",
      " [25876.646]\n",
      " [25948.13 ]\n",
      " [26086.316]\n",
      " [26043.775]\n",
      " [26102.701]\n",
      " [26378.951]\n",
      " [26682.602]\n",
      " [26605.959]\n",
      " [26643.412]\n",
      " [26788.201]\n",
      " [26789.336]\n",
      " [26671.43 ]\n",
      " [26556.047]\n",
      " [26601.744]\n",
      " [26631.31 ]\n",
      " [26783.38 ]\n",
      " [26753.111]\n",
      " [26817.373]\n",
      " [26775.041]\n",
      " [26866.184]\n",
      " [26844.916]\n",
      " [26971.434]\n",
      " [26885.31 ]\n",
      " [26771.127]\n",
      " [26886.143]\n",
      " [26944.559]\n",
      " [26937.04 ]\n",
      " [26817.72 ]\n",
      " [26718.94 ]\n",
      " [26801.326]\n",
      " [26679.38 ]\n",
      " [26345.174]\n",
      " [26382.463]\n",
      " [26172.02 ]\n",
      " [26164.07 ]\n",
      " [25652.32 ]\n",
      " [25906.248]\n",
      " [25993.838]\n",
      " [26183.781]\n",
      " [26071.193]\n",
      " [26070.037]\n",
      " [26250.83 ]\n",
      " [26114.045]\n",
      " [25837.498]\n",
      " [25990.67 ]\n",
      " [25697.732]\n",
      " [25445.926]\n",
      " [25487.346]\n",
      " [25177.186]\n",
      " [25201.627]\n",
      " [25720.451]\n",
      " [25907.605]\n",
      " [26107.166]\n",
      " [26425.018]\n",
      " [26516.521]\n",
      " [26450.834]\n",
      " [26373.545]\n",
      " [26452.494]\n",
      " [26438.791]\n",
      " [26510.264]\n",
      " [26824.887]\n",
      " [26906.068]\n",
      " [27117.725]\n",
      " [27007.139]\n",
      " [27061.88 ]\n",
      " [26913.06 ]\n",
      " [26899.115]\n",
      " [26902.4  ]\n",
      " [26943.63 ]\n",
      " [27064.604]\n",
      " [27101.04 ]\n",
      " [27275.586]\n",
      " [27184.357]\n",
      " [27169.184]\n",
      " [27199.81 ]\n",
      " [27328.482]\n",
      " [27501.463]\n",
      " [27741.828]\n",
      " [27789.28 ]\n",
      " [27756.967]\n",
      " [27645.436]\n",
      " [27633.154]\n",
      " [27576.229]\n",
      " [27591.547]\n",
      " [27699.729]\n",
      " [27627.17 ]\n",
      " [27543.535]\n",
      " [27600.604]\n",
      " [27605.49 ]\n",
      " [27540.771]\n",
      " [27243.139]\n",
      " [27018.525]\n",
      " [26799.693]\n",
      " [26158.877]\n",
      " [26375.674]\n",
      " [26310.588]\n",
      " [26727.059]\n",
      " [26583.518]\n",
      " [26304.695]\n",
      " [26564.744]\n",
      " [25894.318]\n",
      " [25985.271]\n",
      " [26309.582]\n",
      " [26538.695]\n",
      " [26391.406]\n",
      " [26658.834]\n",
      " [26627.832]\n",
      " [26073.717]\n",
      " [26335.756]\n",
      " [26165.299]\n",
      " [26418.518]\n",
      " [26767.951]\n",
      " [26065.752]\n",
      " [26134.291]\n",
      " [26443.69 ]\n",
      " [26773.271]\n",
      " [26812.59 ]\n",
      " [27378.736]\n",
      " [27410.773]\n",
      " [27658.562]\n",
      " [27738.62 ]\n",
      " [27734.03 ]\n",
      " [27590.682]\n",
      " [27636.88 ]\n",
      " [27685.166]\n",
      " [27681.465]\n",
      " [27378.842]\n",
      " [27459.76 ]\n",
      " [27320.24 ]\n",
      " [27453.525]\n",
      " [27400.686]\n",
      " [27399.857]\n",
      " [27496.064]\n",
      " [26974.107]\n",
      " [26475.51 ]\n",
      " [26611.455]\n",
      " [26967.15 ]\n",
      " [26794.33 ]\n",
      " [26579.15 ]\n",
      " [26780.926]\n",
      " [26957.365]\n",
      " [27218.027]\n",
      " [27195.22 ]\n",
      " [27415.037]\n",
      " [27407.814]\n",
      " [27425.154]\n",
      " [27188.428]\n",
      " [27215.59 ]\n",
      " [27190.715]\n",
      " [27215.56 ]\n",
      " [27164.986]\n",
      " [27322.912]\n",
      " [27462.275]\n",
      " [27451.182]\n",
      " [27544.494]\n",
      " [27432.625]\n",
      " [27727.895]\n",
      " [27853.262]\n",
      " [27867.312]\n",
      " [27891.904]\n",
      " [28072.229]\n",
      " [28013.182]\n",
      " [28035.922]\n",
      " [28050.549]\n",
      " [28109.408]\n",
      " [28144.451]\n",
      " [28362.441]\n",
      " [28416.08 ]\n",
      " [28315.951]\n",
      " [28182.693]\n",
      " [28186.9  ]\n",
      " [28297.96 ]\n",
      " [28459.334]\n",
      " [28512.412]\n",
      " [28550.828]\n",
      " [28491.652]\n",
      " [28148.615]\n",
      " [27927.78 ]\n",
      " [28179.908]\n",
      " [28161.154]\n",
      " [28451.416]\n",
      " [28358.22 ]\n",
      " [28341.28 ]\n",
      " [28351.494]\n",
      " [28537.404]\n",
      " [28579.834]\n",
      " [28665.59 ]\n",
      " [28692.928]\n",
      " [28674.37 ]\n",
      " [28855.287]\n",
      " [28806.736]\n",
      " [28928.707]\n",
      " [28919.344]\n",
      " [29029.305]\n",
      " [29027.123]\n",
      " [28938.717]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_scaled_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1678656985960,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "tWGF6iU-saGO",
    "outputId": "e73e77db-22fd-4f0b-db8a-b63059fc79f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  163595.890\n",
      "MAE:  358.269\n",
      "R^2:  0.859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print (f'MSE: {mean_squared_error(y_test, y_pred) : .3f}')\n",
    "print (f'MAE: {mean_absolute_error(y_test, y_pred) : .3f}')\n",
    "print(f'R^2: {r2_score (y_test, y_pred) : .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1678656986084,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "FHYNlOiutaAZ"
   },
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1678656986085,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "X8JLTXVewvaR"
   },
   "outputs": [],
   "source": [
    "HP_HIDDEN = hp.HParam('hidden_size', hp.Discrete([32]))\n",
    "HP_EPOCHS = hp. HParam('epochs', hp.Discrete([100]))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate',hp.RealInterval(0.01, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678656986085,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "tKJu50HUGghl"
   },
   "outputs": [],
   "source": [
    "def train_test_model(hparams, logdir):\n",
    "    model = Sequential([Dense(units=hparams[HP_HIDDEN], activation='relu'),Dense(units=1)])\n",
    "    model.compile(loss='mean_squared_error',optimizer=tf.keras.optimizers.Adam(hparams[HP_LEARNING_RATE]),\n",
    "                  metrics=['mean_squared_error'])\n",
    "    model.fit(X_scaled_train, y_train,validation_data=(X_scaled_test, y_test), \n",
    "              epochs=hparams[HP_EPOCHS],verbose=False, \n",
    "              callbacks=[tf.keras.callbacks.TensorBoard(logdir), \n",
    "              hp.KerasCallback(logdir,hparams), \n",
    "              tf.keras.callbacks.EarlyStopping(monitor= 'val_loss',min_delta=0,patience=200, verbose=0,\n",
    "                                                 mode='auto')])\n",
    "    mse = model.evaluate(X_scaled_test, y_test)[0]\n",
    "    pred = model.predict(X_scaled_test)\n",
    "    r2 = r2_score (y_test, pred)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678656986086,
     "user": {
      "displayName": "Devendra Reddy",
      "userId": "00450031916154439414"
     },
     "user_tz": 300
    },
    "id": "a2kIB5hghbUC"
   },
   "outputs": [],
   "source": [
    "def run(hparams, logdir):\n",
    "    with tf.summary.create_file_writer(logdir).as_default():\n",
    "        hp.hparams_config(hparams=[HP_HIDDEN, HP_EPOCHS, HP_LEARNING_RATE], \n",
    "                          metrics=[hp.Metric('mean_squared_error', display_name='mse'), \n",
    "                                   hp.Metric('r2', display_name='r2')])\n",
    "        mse, r2 = train_test_model(hparams, logdir) \n",
    "        tf.summary.scalar('mean_squared_error', mse, step=1)\n",
    "        tf.summary.scalar('r2', r2, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.01}\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 163236.6719 - mean_squared_error: 163236.6719\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "--- Starting trial: run-1\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.05}\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 56844.1602 - mean_squared_error: 56844.1602\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "--- Starting trial: run-2\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.1}\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175486.4531 - mean_squared_error: 175486.4531\n",
      "8/8 [==============================] - 1s 7ms/step\n",
      "--- Starting trial: run-3\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.14}\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 147331.3750 - mean_squared_error: 147331.3750\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "--- Starting trial: run-4\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.18}\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 138354.9062 - mean_squared_error: 138354.9219\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "--- Starting trial: run-5\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.23}\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 140305.3750 - mean_squared_error: 140305.3750\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "--- Starting trial: run-6\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.27}\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 133781.6094 - mean_squared_error: 133781.6094\n",
      "8/8 [==============================] - 0s 11ms/step\n",
      "--- Starting trial: run-7\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.31}\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 140564.0469 - mean_squared_error: 140564.0469\n",
      "8/8 [==============================] - 1s 24ms/step\n",
      "--- Starting trial: run-8\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.36}\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 198921.0938 - mean_squared_error: 198921.0938\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "--- Starting trial: run-9\n",
      "{'hidden_size': 32, 'epochs': 100, 'learning_rate': 0.4}\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 193022.2031 - mean_squared_error: 193022.2031\n",
      "8/8 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "for hidden in HP_HIDDEN.domain.values:\n",
    "    for epochs in HP_EPOCHS.domain.values:\n",
    "        for learning_rate in np.linspace(0.01,0.4,10):\n",
    "            hparams = {HP_HIDDEN: hidden,\n",
    "                       HP_EPOCHS: epochs, \n",
    "                       HP_LEARNING_RATE: float(\"%.2f\" % float(learning_rate)),\n",
    "                      }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run(hparams, 'logs/hparam_tuning/' + run_name)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rppQ8qLmhb2z"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "Dense (units=16, activation='relu'),\n",
    "Dense (units=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxr3p-t3hb5q"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lR0Yvj8hb7z"
   },
   "outputs": [],
   "source": [
    "model.fit(X_scaled_train, y_train, epochs=1000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HF7N2p2lt1nb"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_scaled_test)[:, 0]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqcwDCKZt6lc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(data_test.index, y_test, c='k')\n",
    "plt.plot(data_test. index, predictions, c='b')\n",
    "plt.plot(data_test.index, predictions, c='r')\n",
    "plt.plot(data_test.index, predictions, c='g')\n",
    "plt.xticks(range (0, 252, 10), rotation=60)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close price')\n",
    "plt. legend(['Truth', 'Neural network prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2DWdTPEFD06vMnTnkLb6k",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
